{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Input\n",
    "from tensorflow.keras.layers import TextVectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-09 16:45:51.097347: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 86ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 4, 0],\n",
       "       [1, 3, 0, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_dataset = tf.data.Dataset.from_tensor_slices([\"foo\", \"bar\", \"baz\"])\n",
    "max_features = 5000  # Maximum vocab size.\n",
    "max_len = 4  # Sequence length to pad the outputs to.\n",
    "\n",
    "embedding_dims = 2\n",
    "\n",
    "# Create the layer.  \n",
    "vectorize_layer = TextVectorization(\n",
    " max_tokens=max_features,\n",
    " output_mode='int',\n",
    " output_sequence_length=max_len)\n",
    "\n",
    "# Now that the vocab layer has been created, call `adapt` on the text-only  \n",
    "# dataset to create the vocabulary. You don't have to batch, but for large  \n",
    "# datasets this means we're not keeping spare copies of the dataset.  \n",
    "vectorize_layer.adapt(text_dataset.batch(64))\n",
    "\n",
    "# Create the model that uses the vectorize text layer  \n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Start by creating an explicit input layer. It needs to have a shape of  \n",
    "# (1,) (because we need to guarantee that there is exactly one string  \n",
    "# input per batch), and the dtype needs to be 'string'.  \n",
    "model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
    "\n",
    "# The first layer in our model is the vectorization layer. After this  \n",
    "# layer, we have a tensor of shape (batch_size, max_len) containing vocab  \n",
    "# indices.  \n",
    "model.add(vectorize_layer)\n",
    "\n",
    "# Now, the model can map strings to integers, and you can add an embedding  \n",
    "# layer to map these integers to learned embeddings.  \n",
    "input_data = [[\"foo qux bar\"], [\"qux baz\"]]\n",
    "model.predict(input_data)\n",
    "#array([[2, 1, 4, 0],\n",
    "#       [1, 3, 0, 0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, Input\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "MAX_LEN = 26\n",
    "MAX_TOKENS = 20000\n",
    "text_dataset = tf.data.Dataset.from_tensor_slices([\"foo\", \"bar\", \"baz\"])\n",
    "preprocessing_layer = TextVectorization(output_sequence_length=26, max_tokens=MAX_TOKENS)\n",
    "preprocessing_layer\n",
    "model = Sequential([\n",
    "    Input(shape = (1, ), dtype=tf.string),\n",
    "    preprocessing_layer\n",
    "])\n",
    "input_data = [[\"foo qux bar\"], [\"qux baz\"]]\n",
    "#model.predict(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dataset = tf.data.Dataset.from_tensor_slices([\"foo\", \"bar\", \"baz\"])\n",
    "\n",
    "#input_data = [[\"foo qux bar\"], [\"qux baz\"]]\n",
    "#model.predict(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step\n",
      "(7, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 10:13:33.707408: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6, 5, 4, 0],\n",
       "       [7, 3, 0, 0],\n",
       "       [6, 5, 4, 0],\n",
       "       [5, 4, 6, 0],\n",
       "       [1, 1, 0, 0],\n",
       "       [8, 6, 0, 0],\n",
       "       [2, 0, 0, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_dataset = tf.data.Dataset.from_tensor_slices([\"titi toto avion tutu tata tztz xylophone\"])#([\"foo foo\", \"bar\", \"baz\"])\n",
    "preprocessing_layer = TextVectorization(max_tokens=9, output_sequence_length=4, output_mode='int')\n",
    "preprocessing_layer.adapt(text_dataset.batch(32))\n",
    "model = Sequential(\n",
    "[\n",
    "    Input(shape = (1, ), dtype=tf.string),\n",
    "    preprocessing_layer\n",
    "])\n",
    "phrases = [[\"titi toto tutu\"], [\"tata tztz\"], [\"titi toto tutu\"], [\"toto tutu titi\"], [\"chacha manoir\"], \n",
    "[\"avion titi\"] ,[\"xylophone\"]]\n",
    "res = model.predict(phrases)\n",
    "print(res.shape)\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['titi', 'toto', 'tutu'] [6 5 4]\n",
      "['tata', 'tztz'] [7 3]\n",
      "['titi', 'toto', 'tutu'] [6 5 4]\n",
      "['toto', 'tutu', 'titi'] [5 4 6]\n",
      "['chacha', 'manoir'] [1 1]\n",
      "['avion', 'titi'] [8 6]\n",
      "['xylophone'] [2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{6: {'titi'},\n",
       " 5: {'toto'},\n",
       " 4: {'tutu'},\n",
       " 7: {'tata'},\n",
       " 3: {'tztz'},\n",
       " 1: {'chacha', 'manoir'},\n",
       " 8: {'avion'},\n",
       " 2: {'xylophone'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrd_i = {}\n",
    "for phi,ph in enumerate(phrases):\n",
    "    wrds = ph[0].split(\" \")\n",
    "    print(wrds, res[phi][:len(wrds)])\n",
    "    for wi in range(len(wrds)):\n",
    "\n",
    "        if res[phi][wi] not in wrd_i.keys():\n",
    "            wrd_i[res[phi][wi]] = set()\n",
    "        wrd_i[res[phi][wi]].add(wrds[wi])\n",
    "wrd_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n",
      "(7, 4, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.03037127,  0.00637014,  0.00581019, -0.01834431,\n",
       "         -0.04895836],\n",
       "        [-0.03744565, -0.02089571,  0.04181359,  0.04433841,\n",
       "         -0.02651073],\n",
       "        [-0.02376949, -0.04465935, -0.01542781, -0.00890397,\n",
       "         -0.01439738],\n",
       "        [-0.00313711, -0.04297994, -0.00152006,  0.03151139,\n",
       "          0.04764477]],\n",
       "\n",
       "       [[ 0.03911985,  0.01901734, -0.01242948,  0.00561763,\n",
       "         -0.01996814],\n",
       "        [-0.04283087,  0.02748943, -0.04682617, -0.04292084,\n",
       "         -0.02758493],\n",
       "        [-0.00313711, -0.04297994, -0.00152006,  0.03151139,\n",
       "          0.04764477],\n",
       "        [-0.00313711, -0.04297994, -0.00152006,  0.03151139,\n",
       "          0.04764477]],\n",
       "\n",
       "       [[ 0.03037127,  0.00637014,  0.00581019, -0.01834431,\n",
       "         -0.04895836],\n",
       "        [-0.03744565, -0.02089571,  0.04181359,  0.04433841,\n",
       "         -0.02651073],\n",
       "        [-0.02376949, -0.04465935, -0.01542781, -0.00890397,\n",
       "         -0.01439738],\n",
       "        [-0.00313711, -0.04297994, -0.00152006,  0.03151139,\n",
       "          0.04764477]],\n",
       "\n",
       "       [[-0.03744565, -0.02089571,  0.04181359,  0.04433841,\n",
       "         -0.02651073],\n",
       "        [-0.02376949, -0.04465935, -0.01542781, -0.00890397,\n",
       "         -0.01439738],\n",
       "        [ 0.03037127,  0.00637014,  0.00581019, -0.01834431,\n",
       "         -0.04895836],\n",
       "        [-0.00313711, -0.04297994, -0.00152006,  0.03151139,\n",
       "          0.04764477]],\n",
       "\n",
       "       [[-0.03533586, -0.03267454,  0.02034542, -0.00669544,\n",
       "          0.04530296],\n",
       "        [-0.03533586, -0.03267454,  0.02034542, -0.00669544,\n",
       "          0.04530296],\n",
       "        [-0.00313711, -0.04297994, -0.00152006,  0.03151139,\n",
       "          0.04764477],\n",
       "        [-0.00313711, -0.04297994, -0.00152006,  0.03151139,\n",
       "          0.04764477]],\n",
       "\n",
       "       [[-0.01215377,  0.01689023,  0.00799979, -0.01215971,\n",
       "          0.03546408],\n",
       "        [ 0.03037127,  0.00637014,  0.00581019, -0.01834431,\n",
       "         -0.04895836],\n",
       "        [-0.00313711, -0.04297994, -0.00152006,  0.03151139,\n",
       "          0.04764477],\n",
       "        [-0.00313711, -0.04297994, -0.00152006,  0.03151139,\n",
       "          0.04764477]],\n",
       "\n",
       "       [[-0.04622537,  0.03430497,  0.03676072,  0.04388554,\n",
       "         -0.00064528],\n",
       "        [-0.00313711, -0.04297994, -0.00152006,  0.03151139,\n",
       "          0.04764477],\n",
       "        [-0.00313711, -0.04297994, -0.00152006,  0.03151139,\n",
       "          0.04764477],\n",
       "        [-0.00313711, -0.04297994, -0.00152006,  0.03151139,\n",
       "          0.04764477]]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding, Dense\n",
    "\n",
    "N_CLASSES = 3\n",
    "\n",
    "text_dataset = tf.data.Dataset.from_tensor_slices([\"titi toto avion tutu tata tztz xylophone\"])#([\"foo foo\", \"bar\", \"baz\"])\n",
    "preprocessing_layer = TextVectorization(max_tokens=9, output_sequence_length=4, output_mode='int')\n",
    "preprocessing_layer.adapt(text_dataset.batch(32))\n",
    "\n",
    "# embedding a 1000 words vocab in 5 words\n",
    "embedding_layer = Embedding(1000, 5)\n",
    "\n",
    "model = Sequential(\n",
    "[\n",
    "    Input(shape = (1, ), dtype=tf.string),\n",
    "    preprocessing_layer,\n",
    "    embedding_layer,\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(N_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "phrases = [[\"titi toto tutu\"], [\"tata tztz\"], [\"titi toto tutu\"], [\"toto tutu titi\"], [\"chacha manoir\"], \n",
    "[\"avion titi\"] ,[\"xylophone\"]]\n",
    "res = model.predict(phrases)\n",
    "print(res.shape)\n",
    "res\n",
    "\n",
    "\n",
    "#text_dataset = tf.data.Dataset.from_tensor_slices([\"titi toto avion tutu tata tztz xylophone\"])\n",
    "#preprocessing_layer(text_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_hub import KerasLayer\n",
    "SWIVEL = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim-with-oov/1\"\n",
    "\n",
    "swivel_module = KerasLayer(SWIVEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.01362136,  0.36039677,  0.4090194 , ..., -0.1157171 ,\n",
       "         -0.59178233,  0.16092265],\n",
       "        [-0.07641025, -0.26564464,  0.44310385, ..., -0.37381256,\n",
       "         -0.1619345 ,  0.0031434 ],\n",
       "        [ 0.55277616,  0.34195077, -0.45784146, ...,  0.18172583,\n",
       "          0.05937071, -0.13633412],\n",
       "        ...,\n",
       "        [ 0.92592955,  0.43907115, -0.13908613, ..., -0.1368552 ,\n",
       "          0.58673716, -0.29491594],\n",
       "        [ 1.1792232 ,  0.08465543,  0.6624093 , ..., -0.48487076,\n",
       "         -0.98878735, -0.57055944],\n",
       "        [ 1.1646788 , -0.20625216,  0.07113393, ..., -0.33484292,\n",
       "         -0.9706867 , -0.4425568 ]], dtype=float32)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swweight = swivel_module.get_weights()\n",
    "swweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19469, 20)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(swweight))\n",
    "swweight[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 20), dtype=float32, numpy=\n",
       "array([[ 0.6402509 , -0.320366  ,  0.39814392,  0.10049738, -0.20162806,\n",
       "         0.04523668, -0.702852  , -0.1462781 , -0.18485829, -1.2666786 ,\n",
       "        -0.72979474,  1.0004414 , -0.22212121, -0.56271666, -0.58339417,\n",
       "         1.1507376 ,  0.70721537,  0.01393132, -0.54767364, -0.05641793]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swivel_module([\"the car is big\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 20), dtype=float32, numpy=\n",
       "array([[ 0.6402509 , -0.320366  ,  0.39814392,  0.10049738, -0.20162806,\n",
       "         0.04523668, -0.702852  , -0.1462781 , -0.18485829, -1.2666786 ,\n",
       "        -0.72979474,  1.0004414 , -0.22212121, -0.56271666, -0.58339417,\n",
       "         1.1507376 ,  0.70721537,  0.01393132, -0.54767364, -0.05641793],\n",
       "       [ 1.0415261 ,  0.9814507 , -0.27379286,  0.30891693, -0.97580093,\n",
       "         1.0505939 , -1.1736104 ,  0.8999038 ,  1.1177965 , -0.50735945,\n",
       "        -0.9517901 ,  1.0200392 , -0.7684101 , -0.31442934, -0.57985973,\n",
       "        -0.72479   , -0.6812028 , -0.8634784 , -1.30937   , -0.39851046]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swivel_module([\"the car is big\", \"the dress is red\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, Dense\n",
    "\n",
    "\n",
    "model_sw = Sequential(\n",
    "[\n",
    "    #Input(shape = (None, 1, ), dtype=tf.string),\n",
    "    #tf.data.Dataset.from_tensor_slices(),\n",
    "    swivel_module,\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 170ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.14964916, 0.8503508 ]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sw.predict([\"the car is big\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
